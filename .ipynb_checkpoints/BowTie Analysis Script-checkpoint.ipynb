{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm inspired by https://github.com/jeroenvldj/bow-tie_detection/blob/master/bow-tie_detection.py\n",
    "\n",
    "def bowtie_analysis(G):\n",
    "    # reverse all direction of the graph\n",
    "    GT = nx.reverse(G, copy=True)\n",
    "    # calculate SSC\n",
    "    SSC = max(list(nx.strongly_connected_components(G)),key=len)    \n",
    "    \n",
    "    \n",
    "    # take any node n from SSC and do a depth first search \n",
    "    # through directed graph beginning from node n\n",
    "    v_any = list(SSC)[0]\n",
    "    DFS_G = set(nx.dfs_tree(G,v_any).nodes())\n",
    "    DFS_GT = set(nx.dfs_tree(GT,v_any).nodes())\n",
    "    OUT = DFS_G - SSC\n",
    "    IN = DFS_GT - SSC\n",
    "    V_rest = set(G.nodes()) - SSC - OUT - IN\n",
    "\n",
    "    TUBES = set()\n",
    "    INTENDRILS = set()\n",
    "    OUTTENDRILS = set()\n",
    "    OTHER = set()\n",
    "\n",
    "    for v in V_rest:\n",
    "        # irv => in reaches node v\n",
    "        irv = len(IN & set(nx.dfs_tree(GT,v).nodes())) is not 0\n",
    "        # vro => node v reaches out\n",
    "        vro = len(OUT & set(nx.dfs_tree(G,v).nodes())) is not 0\n",
    "        if irv and vro:\n",
    "            TUBES.add(v)\n",
    "        elif irv and not vro:\n",
    "            INTENDRILS.add(v)\n",
    "        elif not irv and vro:\n",
    "            OUTTENDRILS.add(v)\n",
    "        elif not irv and not vro:\n",
    "            OTHER.add(v)\n",
    "\n",
    "    FRINGE = set()\n",
    "    DISCONNECTED = set()\n",
    "    for o in OTHER:\n",
    "        # orIT => node o reaches INTENDRILS  \n",
    "        orIT = len(INTENDRILS & set(nx.dfs_tree(G,o))) is not 0\n",
    "        # OTro => OUTTERNDIRLS reaches node o\n",
    "        OTro = len(OUTTENDRILS & set(nx.dfs_tree(GT,o))) is not 0\n",
    "        if orIT or OTro:\n",
    "            FRINGE.add(o)\n",
    "        else:\n",
    "            DISCONNECTED.add(o)\n",
    "    \n",
    "    TENDRILS = INTENDRILS.union(OUTTENDRILS)\n",
    "    \n",
    "    def component_result(name, graph_nodes):\n",
    "        return{ name        : len(graph_nodes),\n",
    "                name + \"_s\" : sum([G.nodes()[node][\"is_sink\"] for node in graph_nodes]),\n",
    "                name + \"_m\" : sum([G.nodes()[node][\"is_miner\"] for node in graph_nodes])}\n",
    "\n",
    "    result_dict = dict()\n",
    "    result_dict.update(component_result(\"nodes\", G.nodes()))\n",
    "    result_dict.update(component_result(\"ssc\", SSC))\n",
    "    result_dict.update(component_result(\"in\", IN))\n",
    "    result_dict.update(component_result(\"out\",OUT))\n",
    "    result_dict.update(component_result(\"tubes\", TUBES))\n",
    "    result_dict.update(component_result(\"tendrils\", TENDRILS))\n",
    "    result_dict.update(component_result(\"fringe\", FRINGE))\n",
    "    result_dict.update(component_result(\"disconnected\", DISCONNECTED))\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_walker(directory, json_output):\n",
    "    d = {}\n",
    "    #files = os.listdir(directory)\n",
    "    files = directory\n",
    "    for file in files:\n",
    "        with open(directory+'/'+file, 'r', encoding='utf8', errors='ignore') as f:\n",
    "            G = nx.read_graphml(f)\n",
    "            bowtie_dict = bowtie_analysis(G)\n",
    "            with open(json_output, \"r+\") as fi:\n",
    "                data = json.load(fi)\n",
    "                new_entry = {file[:-8] : bowtie_dict}\n",
    "                data.update(new_entry)\n",
    "                fi.seek(0)\n",
    "                json.dump(data, fi, indent=4)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = os.listdir(\"data/NET-btc-heur_0-week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "cusse\n",
      "cusse\n",
      "cusse\n",
      "test\n",
      "cusse\n",
      "cusse\n",
      "cusse\n",
      "test\n",
      "cusse\n",
      "cusse\n",
      "cusse\n",
      "test\n",
      "cusse\n",
      "cusse\n",
      "cusse\n",
      "test\n",
      "cusse\n",
      "cusse\n",
      "test\n",
      "cusse\n",
      "cusse\n",
      "test\n",
      "cusse\n",
      "cusse\n",
      "test\n",
      "cusse\n",
      "cusse\n",
      "test\n",
      "cusse\n",
      "cusse\n",
      "test\n",
      "cusse\n",
      "cusse\n",
      "test\n",
      "cusse\n",
      "cusse\n",
      "test\n",
      "cusse\n",
      "cusse\n"
     ]
    }
   ],
   "source": [
    "#nr_cores = multiprocessing.cpu_count()\n",
    "#np_files = np.array(files)\n",
    "#chunk_lst = np.array_split(np_files, nr_cores)\n",
    "\n",
    "p_files = np.array(files)\n",
    "chunk_lst = np.array_split(np_files, 4)\n",
    "\n",
    "counter = 0\n",
    "for i in chunk_lst:\n",
    "    p1.Process(target = file_walker)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['2009-01-26.graphml', '2009-05-04.graphml', '2010-02-08.graphml'],\n",
       "       dtype='<U18'),\n",
       " array(['2010-04-26.graphml', '2010-09-06.graphml', '2010-10-18.graphml'],\n",
       "       dtype='<U18'),\n",
       " array(['2011-10-17.graphml', '2011-10-31.graphml', '2011-11-28.graphml'],\n",
       "       dtype='<U18'),\n",
       " array(['2012-01-30.graphml', '2012-04-23.graphml', '2012-04-30.graphml'],\n",
       "       dtype='<U18'),\n",
       " array(['2012-06-04.graphml', '2012-10-08.graphml'], dtype='<U18'),\n",
       " array(['2012-12-31.graphml', '2013-04-15.graphml'], dtype='<U18'),\n",
       " array(['2013-07-08.graphml', '2013-09-16.graphml'], dtype='<U18'),\n",
       " array(['2013-11-18.graphml', '2014-02-10.graphml'], dtype='<U18'),\n",
       " array(['2014-04-14.graphml', '2014-07-28.graphml'], dtype='<U18'),\n",
       " array(['2014-09-29.graphml', '2014-12-22.graphml'], dtype='<U18'),\n",
       " array(['2015-02-02.graphml', '2015-04-06.graphml'], dtype='<U18'),\n",
       " array(['2015-06-08.graphml', '2015-08-10.graphml'], dtype='<U18')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files_walker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-601349e0c86b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mdb_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mfiles_walker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/NET-btc-heur_0-week\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'files_walker' is not defined"
     ]
    }
   ],
   "source": [
    "# run bow tie analysis\n",
    "json_output = \"test.json\"\n",
    "\n",
    "if not os.path.isfile(json_output):\n",
    "    with io.open(os.path.join(json_output), 'w') as db_file:\n",
    "        db_file.write(json.dumps({}))\n",
    "        \n",
    "files_walker(\"data/NET-btc-heur_0-week\", json_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
